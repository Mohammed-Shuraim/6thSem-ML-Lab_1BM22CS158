{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1BM22CS158 ##Lab-10\n",
        "\n",
        "Implement Dimensionality reduction using Principle\n",
        "\n",
        "Component Analysis (PCA) method.\n",
        "\n",
        "Write Python code to implement the following. Consider dataset files as “heart.csv”\n",
        "\n",
        "Convert text columns to numbers using label encoding and one hot encoding\n",
        "\n",
        "Apply scaling\n",
        "\n",
        "Build a classification model using various methods (SVM, logistic regression, random forest) and\n",
        "check which model gives you the best accuracy\n",
        "\n",
        "Now use PCA to reduce dimensions, retrain your model and see what impact it has on your model\n",
        "in terms of accuracy. Keep in mind that many times doing PCA reduces the accuracy but\n",
        "computation is much lighter and that's the trade off you need to consider while building models in\n",
        "real life.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_dLusD3a6TRD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRKIIq3Z6Cuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0859b3d-a320-4b74-e2c6-f4b9af68a54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Accuracy Without PCA ===\n",
            "Logistic Regression: 0.8525\n",
            "SVM: 0.8689\n",
            "Random Forest: 0.8689\n",
            "\n",
            "=== Accuracy With PCA ===\n",
            "Logistic Regression: 0.8525\n",
            "SVM: 0.8361\n",
            "Random Forest: 0.8525\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MLlab dataset/heart.csv\")\n",
        "\n",
        "# Step 2: Identify categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Step 3: Encode categorical columns using Label Encoding (for binary) or OneHotEncoding (for >2 categories)\n",
        "df_encoded = df.copy()\n",
        "label_enc = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if df_encoded[col].nunique() == 2:\n",
        "        df_encoded[col] = label_enc.fit_transform(df_encoded[col])\n",
        "    else:\n",
        "        df_encoded = pd.get_dummies(df_encoded, columns=[col])\n",
        "\n",
        "# Step 4: Separate features and target\n",
        "X = df_encoded.drop('target', axis=1)\n",
        "y = df_encoded['target']\n",
        "\n",
        "# Step 5: Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 6: Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 7: Train and evaluate models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Random Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "print(\"=== Accuracy Without PCA ===\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{name}: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "\n",
        "# Step 8: Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Step 9: Split PCA-transformed data\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\n=== Accuracy With PCA ===\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    print(f\"{name}: {accuracy_score(y_test, y_pred):.4f}\")\n"
      ]
    }
  ]
}